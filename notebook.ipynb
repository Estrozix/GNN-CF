{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "from project.model import LightGCN, MF\n",
    "from project.utils.loss import BPRLoss\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from functools import partial\n",
    "from project import utils\n",
    "from project.model import light_gcn, mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control variables.\n",
    "TARGET_EDGE = ('user', 'rated', 'item')\n",
    "LR = 1e-3\n",
    "REG_FACTOR = 1e-3\n",
    "STRATEGY = 'triplet'\n",
    "MODEL = 'LightGCN'\n",
    "PATH = (\n",
    "    '/home/jowin/Git/GNN-CF/out/'\n",
    "    '{strategy}/{model}/{reg_factor:.0e}'\n",
    ")\n",
    "\n",
    "# Validates the given controls.\n",
    "assert STRATEGY in ('triplet', 'binary')\n",
    "assert MODEL in ('LightGCN', 'MF')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the datasets to compute the loss.\n",
    "trn_data = torch.load('data/out/trn_Video_Games.pt')\n",
    "vld_data = torch.load('data/out/vld_Video_Games.pt')\n",
    "# Builds the dataset for the all-ranking protocol.\n",
    "rnk_data = torch.load('data/out/rnk_vld_Video_Games.pt')\n",
    "\n",
    "# Extracts the edge attribute indices for all datasets.\n",
    "trn_edge_label_index = trn_data[TARGET_EDGE].edge_label_index\n",
    "vld_edge_label_index = vld_data[TARGET_EDGE].edge_label_index\n",
    "# Extracts the edge label index for the all-ranking data.\n",
    "rnk_edge_label_index = rnk_data[TARGET_EDGE].edge_label_index\n",
    "rnk_edge_label = rnk_data[TARGET_EDGE].edge_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies the shared key-word arguments for the batch loaders.\n",
    "sampler_kwargs = dict(\n",
    "    num_workers=mp.cpu_count() // 2,\n",
    "    pin_memory=True\n",
    ")\n",
    "# Configuring the neighbor sampling scheme.\n",
    "alone_kwargs = dict(**sampler_kwargs, num_neighbors=[ 0])\n",
    "graph_kwargs = dict(**sampler_kwargs, num_neighbors=[-1] * 3)\n",
    "# Configuring the base settings for the loss batch-loaders.\n",
    "loss_kwargs = dict(shuffle=True)\n",
    "# Defines the settings for the training and validation batch-loaders.\n",
    "trn_kwargs = dict(**loss_kwargs,\n",
    "    data=trn_data,\n",
    "    edge_label_index=[TARGET_EDGE, trn_edge_label_index],\n",
    "    batch_size=2048\n",
    ")\n",
    "vld_kwargs = dict(**loss_kwargs,\n",
    "    data=vld_data,\n",
    "    edge_label_index=[TARGET_EDGE, vld_edge_label_index],\n",
    "    batch_size=4096\n",
    ")\n",
    "# Key-word arguments for the loss batch-loaders.\n",
    "triplet_kwargs = dict(neg_sampling='triplet')\n",
    "binary_kwargs = dict(neg_sampling='binary')\n",
    "\n",
    "# Specifying the model parameters.\n",
    "model_kwargs = dict(\n",
    "    num_embeddings=trn_data.num_nodes_dict,\n",
    "    embedding_dim=64\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes the model and applies its implied settings.\n",
    "if MODEL == 'LightGCN':\n",
    "    module = LightGCN(**model_kwargs, \n",
    "        weights=3\n",
    "    )\n",
    "    toolbox = light_gcn\n",
    "    sampler_kwargs_ = graph_kwargs\n",
    "else:\n",
    "    module = MF(**model_kwargs)\n",
    "    toolbox = mf\n",
    "    sampler_kwargs_ = alone_kwargs\n",
    "# Instanciates the learning algorithm and loss criterion.\n",
    "optimizer = Adam(module.parameters(), lr=LR)\n",
    "\n",
    "# Resolves the sampling strategy and its derivatives.\n",
    "if STRATEGY == 'triplet':\n",
    "    strategy_kwargs = triplet_kwargs\n",
    "    loss_fn = BPRLoss(reg_factor=REG_FACTOR)\n",
    "    batch_fn = toolbox.eval_triplet\n",
    "else: \n",
    "    strategy_kwargs = binary_kwargs\n",
    "    loss_fn = BCEWithLogitsLoss()\n",
    "    batch_fn = toolbox.eval_binary\n",
    "\n",
    "# Creates the training and validation batch-loaders.\n",
    "trn_loader = LinkNeighborLoader(\n",
    "    **trn_kwargs, \n",
    "    **strategy_kwargs, \n",
    "    **sampler_kwargs_\n",
    ")\n",
    "vld_loader = LinkNeighborLoader(\n",
    "    **vld_kwargs, \n",
    "    **strategy_kwargs, \n",
    "    **sampler_kwargs_\n",
    ")\n",
    "# Constructs the all-ranking protocol's batch-loader.\n",
    "rnk_loader = LinkNeighborLoader(**sampler_kwargs_,\n",
    "    data=rnk_data,\n",
    "    edge_label_index=[TARGET_EDGE, rnk_edge_label_index],\n",
    "    edge_label=rnk_edge_label,\n",
    "    batch_size=2**14\n",
    ")\n",
    "\n",
    "# Builds the evaluation function.\n",
    "batch_handler = partial(batch_fn, edge_type=TARGET_EDGE)\n",
    "# Builds the update and validate function.\n",
    "update_fn = partial(utils.dispatch_epoch,\n",
    "    loader=trn_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    batch_handler=batch_handler\n",
    ")\n",
    "validate_fn = partial(utils.dispatch_epoch,\n",
    "    loader=vld_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    batch_handler=batch_handler\n",
    ")\n",
    "# Builds the score function.\n",
    "score_fn = partial(utils.rank_score,\n",
    "    loader=rnk_loader,\n",
    "    pred_fn=toolbox.pred,\n",
    "    edge_type=TARGET_EDGE,\n",
    "    score_fns=[\n",
    "        utils.recall_score, \n",
    "        utils.ndcg_score\n",
    "    ],\n",
    "    at_k=20\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constucts the output path.\n",
    "if MODEL == 'LightGCN':\n",
    "    model_dir = 'light_gcn'\n",
    "else:\n",
    "    model_dir = 'mf'\n",
    "out_path = PATH.format(\n",
    "    strategy=STRATEGY,\n",
    "    model=model_dir, \n",
    "    reg_factor=REG_FACTOR\n",
    ")\n",
    "\n",
    "# Initiates the training session.\n",
    "utils.dispatch_session(\n",
    "    module=module,\n",
    "    update_fn=update_fn,\n",
    "    validate_fn=validate_fn,\n",
    "    verbose=True,\n",
    "    num_epochs=32,\n",
    "    path=out_path\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads that epoch's parameters.\n",
    "mdl_path = os.path.join(out_path, 'mdl/32.pt')\n",
    "state_dict = torch.load(mdl_path)\n",
    "# Assigns those parameters to the model.\n",
    "module.load_state_dict(state_dict)\n",
    "\n",
    "# Fetches a device.\n",
    "device = utils.get_device()\n",
    "# Setting up the model for evaluation.\n",
    "module = module.to(device).eval()\n",
    "\n",
    "# Scores the model.\n",
    "scores = score_fn(module, \n",
    "    device=device, \n",
    "    verbose=True\n",
    ")\n",
    "# Outputs the last epoch's scores.\n",
    "print('Score({})'.format(', '.join([\n",
    "    '{:.2%}'.format(score) for score in scores\n",
    "])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the plotting style.\n",
    "sns.set()\n",
    "\n",
    "# Loads the data.\n",
    "frames = []\n",
    "for loss, model, path in [\n",
    "    ['BCE', 'MF',       PATH.format(strategy='binary',  model='mf',        reg_factor=0)],\n",
    "    ['BCE', 'LightGCN', PATH.format(strategy='binary',  model='light_gcn', reg_factor=0)],\n",
    "    ['BPR', 'MF',       PATH.format(strategy='triplet', model='mf',        reg_factor=1e-5)],\n",
    "    ['BPR', 'LightGCN', PATH.format(strategy='triplet', model='light_gcn', reg_factor=1e-4)],\n",
    "]:\n",
    "    path = os.path.join(path, 'trc.pkl')\n",
    "    with open(path, 'rb') as file:\n",
    "        trace = pickle.load(file)\n",
    "    frame = DataFrame(trace) \\\n",
    "        .rename(columns={'update': 'Train', 'validate': 'Validation'}) \\\n",
    "        .rename_axis(index='epoch', columns='dataset') \\\n",
    "        .stack() \\\n",
    "        .rename('loss') \\\n",
    "        .reset_index() \\\n",
    "        .assign(objective=loss, model=model)\n",
    "    frames.append(frame)\n",
    "frame = pd.concat(frames, ignore_index=True)\n",
    "# Specifing which training configuration to be plotted.\n",
    "model, objective = 'LightGCN', 'BCE'\n",
    "# Plots the figure.\n",
    "data = frame.query(f'model == \"{model}\" & objective == \"{objective}\"')\n",
    "if model == 'MF' and objective == 'BCE':\n",
    "    figsize = [3.25, 3]\n",
    "else:\n",
    "    figsize = [3.25 * .9, 3 * .9]\n",
    "fig, ax = plt.subplots(\n",
    "    figsize=figsize, \n",
    "    dpi=256,\n",
    "    tight_layout=True\n",
    ")\n",
    "ax = sns.lineplot(\n",
    "    data=data, \n",
    "    x='epoch',\n",
    "    y='loss',\n",
    "    hue='dataset',\n",
    "    style='dataset',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_xlabel('Epoch')\n",
    "if model == 'MF' and objective == 'BCE':\n",
    "    ax.set_ylabel('Loss')\n",
    "else:\n",
    "    ax.set_ylabel(None)\n",
    "if model == 'LightGCN' and objective == 'BPR':\n",
    "    ax.legend(title='Dataset')\n",
    "else:\n",
    "    ax.get_legend().remove()\n",
    "plt.savefig(\n",
    "    fname=f'out/figures/{objective}-{model}.png',\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0\n",
    ")\n",
    "plt.show(fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
