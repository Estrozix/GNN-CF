{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namespace\n",
    "import torch.nn.functional as f\n",
    "import torch_geometric as pyg\n",
    "import itertools as it\n",
    "# import networkx as nx\n",
    "import torch\n",
    "\n",
    "# Constructor.\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.typing import EdgeType, NodeType\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch.nn.modules.loss import _Loss as Loss\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, Optimizer\n",
    "from torch.nn import (\n",
    "    Dropout1d,\n",
    "    Embedding, \n",
    "    Module, \n",
    "    ModuleDict,\n",
    "    ModuleList, \n",
    "    Linear, \n",
    "    LeakyReLU\n",
    ")\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant.\n",
    "from project.config import TRG_EDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namespace.\n",
    "import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the datasets to compute the loss.\n",
    "trn_data = torch.load('data/out/trn_Video_Games.pt')\n",
    "vld_data = torch.load('data/out/vld_Video_Games.pt')\n",
    "\n",
    "# Extracts the edge attribute indices for all datasets.\n",
    "trn_edge_label_index = trn_data[TRG_EDGE].edge_label_index\n",
    "vld_edge_label_index = vld_data[TRG_EDGE].edge_label_index\n",
    "# Specifies the shared key-word arguments for the batch loaders.\n",
    "kwargs = dict(\n",
    "    num_neighbors=[0],  # [8, 4, 2],\n",
    "    neg_sampling='triplet',\n",
    "    num_workers=10,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "# Creates the sub-graph loaders for the loss .\n",
    "trn_loader = LinkNeighborLoader(**kwargs,\n",
    "    data=trn_data,\n",
    "    edge_label_index=[TRG_EDGE, trn_edge_label_index],\n",
    "    batch_size=2048\n",
    ")\n",
    "vld_loader = LinkNeighborLoader(**kwargs,\n",
    "    data=vld_data,\n",
    "    edge_label_index=[TRG_EDGE, vld_edge_label_index],\n",
    "    batch_size=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the dataset for the all-ranking protocol.\n",
    "rnk_data = torch.load('data/out/rnk_vld_Video_Games.pt')\n",
    "# Extracts the edge label index for the all-ranking data.\n",
    "rnk_edge_label_index = rnk_data[TRG_EDGE].edge_label_index\n",
    "# Creates a batch loader for the all-ranking data.\n",
    "rnk_loader = LinkNeighborLoader(\n",
    "    data=rnk_data,\n",
    "    edge_label_index=[TRG_EDGE, rnk_edge_label_index],\n",
    "    num_neighbors=[0],  # [8, 4, 2],\n",
    "    batch_size=8192,\n",
    "    num_workers=10,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgePredictor(Module):\n",
    "\n",
    "    def __init__(self, *, trg_edge: EdgeType = TRG_EDGE) -> None:\n",
    "        super().__init__()\n",
    "        self.trg_edge = trg_edge\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def trg_src_node(self) -> NodeType:\n",
    "        return self.trg_edge[0]\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def trg_edge_name(self) -> str:\n",
    "        return self.trg_edge[1]\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def trg_dst_node(self) -> NodeType:\n",
    "        return self.trg_edge[2]\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def trg_nodes(self) -> tuple[NodeType, NodeType]:\n",
    "        return (self.trg_src_node, self.trg_dst_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeEmbedding(ModuleDict):\n",
    "\n",
    "    def __init__(self, \n",
    "        num_embeddings: dict[NodeType, int],\n",
    "        embedding_dim: int,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__({\n",
    "            node_type: Embedding(\n",
    "                num_embeddings=num_embeddings,\n",
    "                embedding_dim=embedding_dim, \n",
    "                **kwargs\n",
    "            ) \n",
    "                for node_type, num_embeddings \n",
    "                in num_embeddings.items()\n",
    "        })\n",
    "\n",
    "\n",
    "    def forward(self, n_id_dict: dict[NodeType, Tensor]) -> dict[NodeType, Tensor]:\n",
    "        return {\n",
    "            node_type: self[node_type](n_id) \n",
    "                for node_type, n_id \n",
    "                in n_id_dict.items()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InnerProduct(Module): \n",
    "\n",
    "    def forward(self, x_src: Tensor, x_dst: Tensor) -> Tensor:\n",
    "        return torch.bmm(\n",
    "            x_src.unsqueeze(-2),\n",
    "            x_dst.unsqueeze(-1)\n",
    "        ).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeRegressor(Linear):\n",
    "\n",
    "    def __init__(self, in_dim: int, out_dim: int = 1, bias: bool = False, **kwargs) -> None:\n",
    "        super().__init__(\n",
    "            in_features=in_dim,\n",
    "            out_features=out_dim,\n",
    "            bias=bias,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.weight.data = torch.nn.init.ones_(self.weight.data)\n",
    "        if self.bias:\n",
    "            self.bias.data = torch.nn.init.zeros_(self.bias.data)\n",
    "\n",
    "\n",
    "    def forward(self, x_src: Tensor, x_dst: Tensor) -> Tensor:\n",
    "        return super().forward(x_src * x_dst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(EdgePredictor):\n",
    "\n",
    "    def __init__(self, \n",
    "            num_embeddings: dict[NodeType, int], \n",
    "            embedding_dim: int,\n",
    "            *,\n",
    "            trg_edge: EdgeType,\n",
    "            **kwargs\n",
    "        ) -> None:\n",
    "        super().__init__(trg_edge=trg_edge)\n",
    "        self.embedding = NodeEmbedding(\n",
    "            num_embeddings=num_embeddings, \n",
    "            embedding_dim=embedding_dim,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.regressor = InnerProduct()\n",
    "        \n",
    "\n",
    "    def forward(self, \n",
    "        n_id: dict[NodeType, Tensor], \n",
    "        edge_label_index: dict[EdgeType, Tensor], \n",
    "    ) -> Tensor:\n",
    "        # Constructs the embeddings.\n",
    "        x_src, x_dst = self.embedding({\n",
    "            node_type: n_id[node_type] \n",
    "            for node_type \n",
    "            in self.trg_nodes\n",
    "        }).values()\n",
    "        # Extracts the edges to predict.\n",
    "        i_src, i_dst = edge_label_index[self.trg_edge]\n",
    "        # Computes and returns the predicted scores.\n",
    "        return self.regressor(x_src[i_src], x_dst[i_dst])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(EdgePredictor):\n",
    "\n",
    "    def __init__(self, \n",
    "            num_embeddings: dict[NodeType, int], \n",
    "            embedding_dim: int,\n",
    "            *,\n",
    "            trg_edge: EdgeType,\n",
    "            **kwargs\n",
    "        ) -> None:\n",
    "        super().__init__(trg_edge=trg_edge)\n",
    "        self.embedding = NodeEmbedding(\n",
    "            num_embeddings=num_embeddings, \n",
    "            embedding_dim=embedding_dim,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.regressor = EdgeRegressor(\n",
    "            in_dim=embedding_dim\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, \n",
    "        n_id: dict[NodeType, Tensor], \n",
    "        edge_label_index: dict[EdgeType, Tensor], \n",
    "    ) -> Tensor:\n",
    "        # Constructs the embeddings.\n",
    "        x_src, x_dst = self.embedding({\n",
    "            node_type: n_id[node_type] \n",
    "            for node_type \n",
    "            in self.trg_nodes\n",
    "        }).values()\n",
    "        # Extracts the edges to predict.\n",
    "        i_src, i_dst = edge_label_index[self.trg_edge]\n",
    "        # Computes and returns the predicted scores.\n",
    "        return self.regressor(x_src[i_src], x_dst[i_dst])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Graph Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingPropagationCell(Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "        in_dim: int,\n",
    "        out_dim: int = None, \n",
    "        bias: bool = False,\n",
    "        dropout: float = .5\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.drop = Dropout1d(dropout)\n",
    "        self.loop = Linear(in_dim, out_dim or in_dim, bias=bias)\n",
    "        self.intr = Linear(in_dim, out_dim or in_dim, bias=bias)\n",
    "        self.actv = LeakyReLU()\n",
    "\n",
    "    \n",
    "    def forward(self, \n",
    "        x_src: Tensor, \n",
    "        x_dst: Tensor, \n",
    "        edge_index: Tensor,\n",
    "        edge_weight: Tensor = None\n",
    "    ) -> Tensor:\n",
    "        # Applies the node dropout.\n",
    "        x_src = self.drop(x_src)  # node dropout\n",
    "        x_dst = self.drop(x_dst)  # node dropout\n",
    "        # Computes the messages to pass.\n",
    "        i_src, i_dst = edge_index\n",
    "        z_src = self.loop(x_src)[i_src]\n",
    "        z_int = self.intr(x_src[i_src] * x_dst[i_dst])\n",
    "        z_msg = edge_weight * (z_src + z_int)\n",
    "        z_msg = self.drop(z_msg)  # message dropout\n",
    "        z_sum = pyg.utils.scatter(z_msg, i_dst, \n",
    "            dim_size=x_dst.size(0)\n",
    "        )\n",
    "        # Computes the self-messages.\n",
    "        z_dst = self.loop(x_dst)\n",
    "        z_dst = self.drop(z_dst)  # message dropout\n",
    "        # Computes the new embeddings and returns them.\n",
    "        x_new = self.actv(z_dst + z_sum)\n",
    "        return x_new\n",
    "    \n",
    "\n",
    "class EmbeddingPropagationLayer(ModuleDict):\n",
    "\n",
    "    def __init__(self, \n",
    "            edge_types: list[EdgeType], \n",
    "            in_dim: int, \n",
    "            out_dim: int = None, \n",
    "            **kwargs\n",
    "        ) -> None:\n",
    "        super().__init__({\n",
    "            edge_label: EmbeddingPropagationCell(\n",
    "                in_dim=in_dim, \n",
    "                out_dim=out_dim, \n",
    "                **kwargs\n",
    "            )\n",
    "                for (_, edge_label, _)\n",
    "                in edge_types\n",
    "        })\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "        x: dict[NodeType, Tensor], \n",
    "        edge_index: dict[EdgeType, Tensor], \n",
    "        edge_weight: dict[EdgeType, Tensor]\n",
    "    ) -> dict[NodeType, Tensor]:\n",
    "        return {\n",
    "            dst_node: self[edge_label](\n",
    "                x_src=x[src_node], \n",
    "                x_dst=x[dst_node], \n",
    "                edge_index=edge_index[\n",
    "                    src_node, edge_label, dst_node\n",
    "                ],\n",
    "                edge_weight=edge_weight[\n",
    "                    src_node, edge_label, dst_node\n",
    "                ]\n",
    "            )\n",
    "                for src_node, edge_label, dst_node \n",
    "                in edge_index\n",
    "        }\n",
    "    \n",
    "\n",
    "class EmbeddingPropagation(ModuleList):\n",
    "    \n",
    "    def __init__(self, \n",
    "        embedding_dims: list[int], \n",
    "        edge_types: list[EdgeType],\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__([\n",
    "            EmbeddingPropagationLayer(\n",
    "                edge_types=edge_types,\n",
    "                in_dim=in_dim,\n",
    "                out_dim=out_dim,\n",
    "                **kwargs\n",
    "            ) \n",
    "                for in_dim, out_dim \n",
    "                in it.pairwise(embedding_dims)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "        x: dict[NodeType, Tensor], \n",
    "        edge_index: dict[EdgeType, Tensor]\n",
    "    ) -> dict[NodeType, Tensor]:\n",
    "        # Constructs the edge weights.\n",
    "        edge_weight = {\n",
    "            edge_type: (\n",
    "                pyg.utils.degree(i_src)[i_src]\n",
    "                *\n",
    "                pyg.utils.degree(i_dst)[i_dst]\n",
    "            ).pow(-.5).unsqueeze(-1)\n",
    "            for edge_type, (i_src, i_dst)\n",
    "            in edge_index.items()\n",
    "        }\n",
    "        # Applies the embedding propagation layers.\n",
    "        xs = [x]\n",
    "        for module in self:\n",
    "            x = module(x, edge_index, edge_weight)\n",
    "            xs.append(x)\n",
    "        # Concatenates all layers' embeddings and returns them.\n",
    "        x_new = {\n",
    "            node_type: torch.cat([\n",
    "                    x_[node_type] for x_ in xs\n",
    "            ], dim=-1) for node_type in x.keys()\n",
    "        }\n",
    "        return x_new\n",
    "    \n",
    "\n",
    "class EdgeRegressor(Linear): \n",
    "\n",
    "    def __init__(self, \n",
    "        in_features: int,\n",
    "        out_features: int = 1,\n",
    "        *,\n",
    "        bias: bool = True,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(in_features, out_features, bias=bias, **kwargs)\n",
    "\n",
    "\n",
    "    def forward(self, x_src: Tensor, x_dst: Tensor) -> Tensor:\n",
    "        return super().forward(x_src * x_dst)\n",
    "\n",
    "\n",
    "# class EdgeRegressor(Module): \n",
    "\n",
    "#     def forward(self, x_src: Tensor, x_dst: Tensor) -> Tensor:\n",
    "#         return (x_src * x_dst).sum(-1)\n",
    "    \n",
    "    \n",
    "class NGCF(Module): \n",
    "\n",
    "    def __init__(self, \n",
    "        num_embeddings: dict[NodeType, int], \n",
    "        embedding_dims: list[int], \n",
    "        *,\n",
    "        edge_types: list[EdgeType],\n",
    "        src_node: NodeType,\n",
    "        dst_node: NodeType,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = NodeEmbedding(\n",
    "            num_embeddings=num_embeddings, \n",
    "            embedding_dim=embedding_dims[0]\n",
    "        )\n",
    "        self.propagation = EmbeddingPropagation(\n",
    "            embedding_dims=embedding_dims, \n",
    "            edge_types=edge_types,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.regressor = EdgeRegressor(\n",
    "            in_features=sum(embedding_dims)\n",
    "        )\n",
    "        # self.regressor = EdgeRegressor()\n",
    "        self.src_node = src_node\n",
    "        self.dst_node = dst_node\n",
    "    \n",
    "\n",
    "    def forward(self, \n",
    "            n_id: dict[NodeType, Tensor],\n",
    "            edge_index: dict[EdgeType, Tensor],\n",
    "            edge_label_index: Tensor\n",
    "        ) -> Tensor:\n",
    "        # Generates and propagates the node embeddings.\n",
    "        x = self.embedding(n_id)\n",
    "        x = self.propagation(x, edge_index)\n",
    "        # Computes the rank predictions and returns them.\n",
    "        y = self.regressor(\n",
    "            x[self.src_node][edge_label_index[0]], \n",
    "            x[self.dst_node][edge_label_index[1]]\n",
    "        )\n",
    "        # Returns the modified dataset.\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispatch_epoch(\n",
    "    module: type[Module], \n",
    "    loader: type[DataLoader],\n",
    "    criterion: type[Loss],\n",
    "    *,\n",
    "    batch_handler: callable,\n",
    "    optimizer: type[Optimizer] = None, \n",
    "    device: torch.device = None,\n",
    "    verbose: bool | int = None\n",
    ") -> list[float]:\n",
    "\n",
    "    # Ensures a device is specified.\n",
    "    if device is None:\n",
    "        device = torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        )\n",
    "    # Sends the model to the specified device.\n",
    "    module = module.to(device)\n",
    "\n",
    "    # Initializes the data structures for the verbose output.\n",
    "    if verbose:\n",
    "        cum_loss = 0\n",
    "\n",
    "    # Initializes the loss trace buffer.\n",
    "    loss_trace = []\n",
    "    # Iterates over the data-loader's batches.\n",
    "    for batch_id, batch in enumerate(loader, start=1):\n",
    "\n",
    "        # Resets the gradient if an optimizer exists.\n",
    "        if optimizer:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Constructs the design and target data structures.\n",
    "        loss = batch_handler(module, batch, criterion, \n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Updates the module, if an optimizer has been given\n",
    "        if optimizer:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Logs the computed loss.\n",
    "        loss = loss.item()\n",
    "        loss_trace.append(loss)\n",
    "        \n",
    "        # Handles the verbose messaging, if verbose is set.\n",
    "        if verbose:\n",
    "            # Updates the cumulative loss sum.\n",
    "            cum_loss += loss\n",
    "            # Outputs the current statistics, if the correct index is present.\n",
    "            if batch_id % verbose == 0:\n",
    "                # Updates the tracked statistics.\n",
    "                avg_loss = cum_loss / batch_id\n",
    "                # Outputs the tracked staistics.\n",
    "                print(\n",
    "                    f'Batch({batch_id}): '\n",
    "                    f'CumAvgLoss({avg_loss:.4f}) & '\n",
    "                    f'BatchLoss({loss:.4f})',\n",
    "                    end='\\r',\n",
    "                    flush=True\n",
    "                )\n",
    "    \n",
    "    # Returns the traced loss.\n",
    "    return loss_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_handler(\n",
    "        data: HeteroData, \n",
    "        x: dict[NodeType, Tensor],\n",
    "        *,\n",
    "        src_node: NodeType,\n",
    "        dst_node: NodeType\n",
    "    ) -> tuple[Tensor, Tensor, Tensor]:\n",
    "    \n",
    "    # Extracts the source and destination nodes' indices.\n",
    "    i_src = data[src_node].src_index\n",
    "    i_pos = data[dst_node].dst_pos_index\n",
    "    i_neg = data[dst_node].dst_neg_index\n",
    "\n",
    "    # Constructs the node types' feature matrices.\n",
    "    x_src = x[src_node][i_src]\n",
    "    x_pos = x[dst_node][i_pos]\n",
    "    x_neg = x[dst_node][i_neg]\n",
    "\n",
    "    # Returns the source, positive and negative features.\n",
    "    return x_src, x_pos, x_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mf_handler(\n",
    "    module: type[EdgePredictor], \n",
    "    data: HeteroData, \n",
    "    criterion: type[Loss],\n",
    "    *,\n",
    "    device: torch.device\n",
    ") -> Tensor:\n",
    "    \n",
    "    # Sends the items to the correct device.\n",
    "    data = data.to(device)\n",
    "    # Computes the embedding propegation.\n",
    "    x = module.embedding(data.n_id_dict)\n",
    "\n",
    "    # Extracts the node target features.\n",
    "    x_src, x_pos, x_neg = triplet_handler(data, x,\n",
    "        src_node=module.trg_src_node,\n",
    "        dst_node=module.trg_dst_node\n",
    "    )\n",
    "\n",
    "    # Computes the link scores.\n",
    "    y_pos = module.regressor(x_src, x_pos)\n",
    "    y_neg = module.regressor(x_src, x_neg)\n",
    "    # Computes the loss.\n",
    "    loss = criterion(y_pos, y_neg)\n",
    "\n",
    "    # Returns the loss.\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRLoss(Loss):\n",
    "\n",
    "    def forward(self, y_pos: Tensor, y_neg: Tensor) -> Tensor:\n",
    "        return - f.logsigmoid(y_pos - y_neg).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(trn_loader))\n",
    "model = MF(\n",
    "    num_embeddings=data.num_nodes_dict,\n",
    "    embedding_dim=64,\n",
    "    trg_edge=TRG_EDGE\n",
    ")\n",
    "display(model)\n",
    "\n",
    "# Instanciates the learning algorithm and loss criterion.\n",
    "optimizer = Adam(model.parameters(), \n",
    "    lr=1e-2,\n",
    "    weight_decay=2e-6\n",
    ")\n",
    "criterion = BPRLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clears the GPU cache.\n",
    "torch.cuda.empty_cache()\n",
    "bst_loss = float('inf')\n",
    "trn_trace = []\n",
    "vld_trace = []\n",
    "for epoch_id in range(1, 16+1):\n",
    "    print(f'Epoch({epoch_id})')\n",
    "\n",
    "    # Dispatches one epoch of training.\n",
    "    trn_loss = dispatch_epoch(\n",
    "        module=model,\n",
    "        loader=trn_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        batch_handler=mf_handler,\n",
    "        verbose=32\n",
    "    )\n",
    "    trn_trace.append(trn_loss)\n",
    "    print()\n",
    "\n",
    "    # Dispatches one epoch of validation.\n",
    "    with torch.no_grad():\n",
    "        vld_loss = dispatch_epoch(\n",
    "            module=model,\n",
    "            loader=vld_loader,\n",
    "            criterion=criterion,\n",
    "            batch_handler=mf_handler,\n",
    "            verbose=32\n",
    "        )\n",
    "    vld_trace.append(vld_loss)\n",
    "    print()\n",
    "\n",
    "    # Keeps the best model.\n",
    "    avg_loss = sum(vld_loss) / len(vld_loss)\n",
    "    if bst_loss > avg_loss:\n",
    "        bst_loss = avg_loss\n",
    "        bst_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "# Reinstates the best model paramters.\n",
    "model.load_state_dict(bst_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vld_ranker = MetricSampleLoader(\n",
    "    data=vld_data,\n",
    "    edge_label_index=[TRG_EDGE, vld_edge_label_index],\n",
    "    num_neighbors=[0],\n",
    "    num_workers=10,\n",
    "    batch_size=512,\n",
    "    pin_memory=True,\n",
    "    neg_ratio=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_score(labels: Tensor, index: Tensor) -> Tensor:\n",
    "    return labels[index].float().mean()\n",
    "\n",
    "\n",
    "def recall_score(labels: Tensor, index: Tensor) -> Tensor:\n",
    "    return labels[index].sum() / labels.sum()\n",
    "\n",
    "\n",
    "def ap_score(labels: Tensor, index: Tensor) -> Tensor:\n",
    "    indicator = labels[index]\n",
    "    precision = indicator.cumsum(0) / torch.arange(1, indicator.size(0) + 1)\n",
    "    return (indicator * precision).sum() / indicator.sum()\n",
    "\n",
    "\n",
    "def ndcg_score(labels: Tensor, index: Tensor, *, coefs: Tensor = None) -> Tensor:\n",
    "    if coefs is None:\n",
    "        coefs = torch.log2(2 + torch.arange(index.size(0)))\n",
    "    return (labels[index] * coefs).sum() / coefs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating function input.\n",
    "loader = vld_ranker\n",
    "module = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_node, dst_node = module.trg_nodes\n",
    "buffer = {}\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm.tqdm(loader):\n",
    "        output = module(\n",
    "            n_id=batch.n_id_dict, \n",
    "            edge_label_index=batch.edge_label_index_dict\n",
    "        ).squeeze()\n",
    "        src_id, dst_id = batch[module.trg_nodes].edge_label_index\n",
    "        src_uid = src_id.unique()\n",
    "        src_mask = src_uid.unsqueeze(1) == src_id.unsqueeze(0)\n",
    "        edge_label = batch[module.trg_nodes].edge_label\n",
    "        for id, mask in zip(src_uid, src_mask):\n",
    "            id = id.item()\n",
    "            if id not in buffer:\n",
    "                buffer[id] = ([], [], [])\n",
    "            scores, ids, labels = buffer[id]\n",
    "            scores.append(output[mask])\n",
    "            ids.append(dst_id[mask])\n",
    "            labels.append(edge_label[mask])\n",
    "buffer = {\n",
    "    src_id: tuple(\n",
    "        torch.cat(buffer) for buffer in buffers\n",
    "    ) \n",
    "    for src_id, buffers in buffer.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_k = 20\n",
    "metrics = []\n",
    "for scores, _, labels in buffer.values():\n",
    "    index = torch.topk(scores, k=min(scores.size(0), at_k)).indices\n",
    "    precision = precision_score(labels, index)\n",
    "    recall = recall_score(labels, index)\n",
    "    ap = ap_score(labels, index)\n",
    "    ndcg = ndcg_score(labels, index)\n",
    "    metrics.append([precision, recall, ap, ndcg])\n",
    "precision, recall, map, ndcg = torch.tensor(metrics).mean(0).tolist()\n",
    "print(f'Precision@{at_k}({precision:.2%})')\n",
    "print(f'Recall@{at_k}({recall:.2%})')\n",
    "print(f'MAP@{at_k}({map:.2%})')\n",
    "print(f'NDCG@{at_k}({ndcg:.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namespace.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Constructor.\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "# Setting the plotting style.\n",
    "sns.set()\n",
    "\n",
    "# Typing.\n",
    "TraceType = list[list[float]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trace(trace: TraceType) -> DataFrame:\n",
    "    return DataFrame(trace) \\\n",
    "        .rename_axis(index='epoch', columns='batch') \\\n",
    "        .transpose() \\\n",
    "        .stack() \\\n",
    "        .rename('loss') \\\n",
    "        .reset_index()\n",
    "\n",
    "\n",
    "def make_frame(traces: list[TraceType], *, labels: list[str]) -> DataFrame:\n",
    "    return pd.concat([\n",
    "        parse_trace(trace).assign(trace=label) \n",
    "        for label, trace in zip(labels, traces)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformats the loss traces.\n",
    "trace = make_frame(\n",
    "    traces=[trn_trace, vld_trace], \n",
    "    labels=['Train', 'Valid.']\n",
    ")\n",
    "\n",
    "# Plots the loss trace.\n",
    "fig, ax = plt.subplots(figsize=[7, 3], dpi=192)\n",
    "ax = sns.lineplot(\n",
    "    data=trace, \n",
    "    x='epoch', \n",
    "    y='loss', \n",
    "    hue='trace', \n",
    "    style='trace', \n",
    "    errorbar='sd', \n",
    "    ax=ax\n",
    ")\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Average Loss')\n",
    "ax.legend(title='Dataset')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngcf_handler(\n",
    "    module: type[Module], \n",
    "    data: HeteroData, \n",
    "    criterion: type[Loss],\n",
    "    *,\n",
    "    device: torch.device\n",
    ") -> Tensor:\n",
    "    \n",
    "    # Sends the items to the correct device.\n",
    "    data = data.to(device)\n",
    "\n",
    "    # Computes the embedding propegation.\n",
    "    x = module.embedding(data.n_id_dict)\n",
    "    x = module.propagation(x, data.edge_index_dict)\n",
    "    # Extracts the source nodes' features.\n",
    "    i_src = data['user'].src_index\n",
    "    x_src = x['user'][i_src]\n",
    "    # Constructs the positive and negative feature matrices.\n",
    "    i_pos = data['item'].dst_pos_index\n",
    "    i_neg = data['item'].dst_neg_index\n",
    "    x_pos = x['item'][i_pos]\n",
    "    x_neg = x['item'][i_neg]\n",
    "    # Computes the link scores.\n",
    "    y_pos = module.regressor(x_src, x_pos)\n",
    "    y_neg = module.regressor(x_src, x_neg)\n",
    "\n",
    "    # Computes the loss.\n",
    "    loss = criterion(y_pos, y_neg)\n",
    "\n",
    "    # Returns the loss.\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes the neural graph model.\n",
    "ngcf = NGCF(\n",
    "    num_embeddings=data.num_nodes_dict,\n",
    "    embedding_dims=[16] * 5,\n",
    "    edge_types=data.edge_types,\n",
    "    src_node='user',\n",
    "    dst_node='item',\n",
    "    dropout=.1,\n",
    ")\n",
    "display(ngcf)\n",
    "\n",
    "# Instanciates the learning algorithm and loss criterion.\n",
    "optimizer = Adam(ngcf.parameters(), \n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "criterion = BPRLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clears the GPU cache.\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trn_trace = []\n",
    "vld_trace = []\n",
    "for epoch_id in range(1, 16+1):\n",
    "    print(f'Epoch({epoch_id})')\n",
    "\n",
    "    # Dispatches one epoch of training.\n",
    "    trn_loss = dispatch_epoch(\n",
    "        module=ngcf,\n",
    "        loader=trn_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        batch_handler=ngcf_handler,\n",
    "        verbose=16\n",
    "    )\n",
    "    trn_trace.append(trn_loss)\n",
    "    print()\n",
    "\n",
    "    # Dispatches one epoch of validation.\n",
    "    with torch.no_grad():\n",
    "        vld_loss = dispatch_epoch(\n",
    "            module=ngcf,\n",
    "            loader=vld_loader,\n",
    "            criterion=criterion,\n",
    "            batch_handler=ngcf_handler,\n",
    "            verbose=16\n",
    "        )\n",
    "    vld_trace.append(vld_loss)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
