{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "from project.model import LightGCN, MF\n",
    "from project.utils.loss import BPRLoss\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from functools import partial\n",
    "from project import utils\n",
    "from project.model import light_gcn, mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control variables.\n",
    "TARGET_EDGE = ('user', 'rated', 'item')\n",
    "TRAIN = True\n",
    "LR = 1e-3\n",
    "REG_FACTOR = 1e-3\n",
    "STRATEGY = 'triplet'\n",
    "MODEL = 'LightGCN'\n",
    "PATH = (\n",
    "    '/home/estro/Documents/Code/GNN-CF/out/'\n",
    "    '{strategy}/{model}/{reg_factor:.0e}'\n",
    ")\n",
    "\n",
    "# Validates the given control parameters.\n",
    "assert STRATEGY in ('binary', 'triplet')\n",
    "assert MODEL in ('MF', 'LightGCN')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the datasets to compute the loss.\n",
    "trn_data = torch.load('data/out/trn_Video_Games.pt')\n",
    "vld_data = torch.load('data/out/vld_Video_Games.pt')\n",
    "# Builds the dataset for the all-ranking protocol.\n",
    "rnk_data = torch.load('data/out/rnk_tst_Video_Games.pt')\n",
    "\n",
    "# Extracts the edge attribute indices for all datasets.\n",
    "trn_edge_label_index = trn_data[TARGET_EDGE].edge_label_index\n",
    "vld_edge_label_index = vld_data[TARGET_EDGE].edge_label_index\n",
    "# Extracts the edge label index for the all-ranking data.\n",
    "rnk_edge_label_index = rnk_data[TARGET_EDGE].edge_label_index\n",
    "rnk_edge_label = rnk_data[TARGET_EDGE].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1muser\u001b[0m={\n",
       "    num_nodes=1540618,\n",
       "    n_id=[1540618]\n",
       "  },\n",
       "  \u001b[1mitem\u001b[0m={\n",
       "    num_nodes=71982,\n",
       "    n_id=[71982]\n",
       "  },\n",
       "  \u001b[1m(user, rated, item)\u001b[0m={\n",
       "    edge_index=[2, 2560219],\n",
       "    e_id=[2560219],\n",
       "    edge_label=[2560219],\n",
       "    edge_label_index=[2, 2560219]\n",
       "  },\n",
       "  \u001b[1m(item, rated_by, user)\u001b[0m={\n",
       "    edge_index=[2, 2560219],\n",
       "    e_id=[2560219]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_device()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies the shared key-word arguments for the batch loaders.\n",
    "sampler_kwargs = dict(\n",
    "    num_workers=mp.cpu_count() // 2,\n",
    "    pin_memory=False\n",
    ")\n",
    "# Configuring the neighbor sampling scheme.\n",
    "alone_kwargs = dict(**sampler_kwargs, num_neighbors=[ 0])\n",
    "graph_kwargs = dict(**sampler_kwargs, num_neighbors=[-1] * 3)\n",
    "# Configuring the base settings for the loss batch-loaders.\n",
    "loss_kwargs = dict(shuffle=True)\n",
    "# Defines the settings for the training and validation batch-loaders.\n",
    "trn_kwargs = dict(**loss_kwargs,\n",
    "    data=trn_data,\n",
    "    edge_label_index=[TARGET_EDGE, trn_edge_label_index],\n",
    "    batch_size=64\n",
    ")\n",
    "vld_kwargs = dict(**loss_kwargs,\n",
    "    data=vld_data,\n",
    "    edge_label_index=[TARGET_EDGE, vld_edge_label_index],\n",
    "    batch_size=64\n",
    ")\n",
    "# Key-word arguments for the loss batch-loaders.\n",
    "triplet_kwargs = dict(neg_sampling='triplet')\n",
    "binary_kwargs = dict(neg_sampling='binary')\n",
    "\n",
    "# Specifying the model parameters.\n",
    "model_kwargs = dict(\n",
    "    num_embeddings=trn_data.num_nodes_dict,\n",
    "    embedding_dim=8\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes the model and applies its implied settings.\n",
    "if MODEL == 'LightGCN':\n",
    "    module = LightGCN(**model_kwargs, \n",
    "        weights=3\n",
    "    )\n",
    "    toolbox = light_gcn\n",
    "    sampler_kwargs_ = graph_kwargs\n",
    "else:\n",
    "    module = MF(**model_kwargs)\n",
    "    toolbox = mf\n",
    "    sampler_kwargs_ = alone_kwargs\n",
    "# Instanciates the learning algorithm and loss criterion.\n",
    "optimizer = Adam(module.parameters(), lr=LR)\n",
    "\n",
    "# Resolves the sampling strategy and its derivatives.\n",
    "if STRATEGY == 'triplet':\n",
    "    strategy_kwargs = triplet_kwargs\n",
    "    loss_fn = BPRLoss(reg_factor=REG_FACTOR)\n",
    "    batch_fn = toolbox.eval_triplet\n",
    "else: \n",
    "    strategy_kwargs = binary_kwargs\n",
    "    loss_fn = BCEWithLogitsLoss()\n",
    "    batch_fn = toolbox.eval_binary\n",
    "\n",
    "# Creates the training and validation batch-loaders.\n",
    "trn_loader = LinkNeighborLoader(\n",
    "    **trn_kwargs, \n",
    "    **strategy_kwargs, \n",
    "    **sampler_kwargs_\n",
    ")\n",
    "vld_loader = LinkNeighborLoader(\n",
    "    **vld_kwargs, \n",
    "    **strategy_kwargs, \n",
    "    **sampler_kwargs_\n",
    ")\n",
    "# Constructs the all-ranking protocol's batch-loader.\n",
    "rnk_loader = LinkNeighborLoader(**sampler_kwargs_,\n",
    "    data=rnk_data,\n",
    "    edge_label_index=[TARGET_EDGE, rnk_edge_label_index],\n",
    "    edge_label=rnk_edge_label,\n",
    "    batch_size=2**14\n",
    ")\n",
    "\n",
    "# Builds the evaluation function.\n",
    "batch_handler = partial(batch_fn, edge_type=TARGET_EDGE)\n",
    "# Builds the update and validate function.\n",
    "update_fn = partial(utils.dispatch_epoch,\n",
    "    loader=trn_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    batch_handler=batch_handler\n",
    ")\n",
    "validate_fn = partial(utils.dispatch_epoch,\n",
    "    loader=vld_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    batch_handler=batch_handler\n",
    ")\n",
    "# Builds the ranking score function.\n",
    "rank_fn = partial(utils.rank_k,\n",
    "    loader=rnk_loader,\n",
    "    pred_fn=toolbox.pred,\n",
    "    edge_type=TARGET_EDGE,\n",
    "    at_k=20\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40004 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/40004 [00:51<115:24:10, 10.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# Potentially initiates the training session.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mif\u001b[39;00m TRAIN:\n\u001b[0;32m---> 14\u001b[0m     utils\u001b[39m.\u001b[39;49mdispatch_session(\n\u001b[1;32m     15\u001b[0m         module\u001b[39m=\u001b[39;49mmodule,\n\u001b[1;32m     16\u001b[0m         update_fn\u001b[39m=\u001b[39;49mupdate_fn,\n\u001b[1;32m     17\u001b[0m         validate_fn\u001b[39m=\u001b[39;49mvalidate_fn,\n\u001b[1;32m     18\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     19\u001b[0m         num_epochs\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     20\u001b[0m         path\u001b[39m=\u001b[39;49mout_path\n\u001b[1;32m     21\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Code/GNN-CF/project/utils/train.py:108\u001b[0m, in \u001b[0;36mdispatch_session\u001b[0;34m(module, update_fn, num_epochs, path, device, validate_fn, score_fn, verbose)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch(\u001b[39m\u001b[39m{\u001b[39;00mepoch_index\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[39m# Updates the model.\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m loss \u001b[39m=\u001b[39m update_fn(module, \n\u001b[1;32m    109\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose, \n\u001b[1;32m    110\u001b[0m     device\u001b[39m=\u001b[39;49mdevice\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m trace[\u001b[39m'\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/Documents/Code/GNN-CF/project/utils/train.py:49\u001b[0m, in \u001b[0;36mdispatch_epoch\u001b[0;34m(module, loader, loss_fn, batch_handler, optimizer, device, verbose)\u001b[0m\n\u001b[1;32m     46\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     48\u001b[0m \u001b[39m# Computes the loss.\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m loss \u001b[39m=\u001b[39m batch_handler(module, batch, loss_fn, \n\u001b[1;32m     50\u001b[0m     device\u001b[39m=\u001b[39;49mdevice\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[39m# Updates the module, if an optimizer has been given\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m optimizer:\n",
      "File \u001b[0;32m~/Documents/Code/GNN-CF/project/model/light_gcn.py:208\u001b[0m, in \u001b[0;36meval_triplet\u001b[0;34m(module, data, loss_fn, edge_type, device)\u001b[0m\n\u001b[1;32m    206\u001b[0m itm_edge_index \u001b[39m=\u001b[39m data[itm_node, usr_node]\u001b[39m.\u001b[39medge_index\n\u001b[1;32m    207\u001b[0m \u001b[39m# Computes the embedding propegation.\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m usr_x, itm_x \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    209\u001b[0m     usr_n_id\u001b[39m=\u001b[39;49m(usr_node, data[usr_node]\u001b[39m.\u001b[39;49mn_id),\n\u001b[1;32m    210\u001b[0m     itm_n_id\u001b[39m=\u001b[39;49m(itm_node, data[itm_node]\u001b[39m.\u001b[39;49mn_id),\n\u001b[1;32m    211\u001b[0m     usr_edge_index\u001b[39m=\u001b[39;49musr_edge_index,\n\u001b[1;32m    212\u001b[0m     itm_edge_index\u001b[39m=\u001b[39;49mitm_edge_index\n\u001b[1;32m    213\u001b[0m )\n\u001b[1;32m    214\u001b[0m \u001b[39m# Extracts the sought feature tensors.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m usr_x, itm_pos_x, itm_neg_x \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mget_triplet_xs(data, \n\u001b[1;32m    216\u001b[0m     x\u001b[39m=\u001b[39m{\n\u001b[1;32m    217\u001b[0m         usr_node: usr_x, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m     dst_node\u001b[39m=\u001b[39mitm_node\n\u001b[1;32m    222\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Code/GNN-CF/project/model/light_gcn.py:151\u001b[0m, in \u001b[0;36mLGCEmbedding.forward\u001b[0;34m(self, usr_n_id, itm_n_id, usr_edge_index, itm_edge_index)\u001b[0m\n\u001b[1;32m    146\u001b[0m usr_x, itm_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding({\n\u001b[1;32m    147\u001b[0m     usr_node: usr_n_id,\n\u001b[1;32m    148\u001b[0m     itm_node: itm_n_id\n\u001b[1;32m    149\u001b[0m })\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    150\u001b[0m \u001b[39m# Propagates the node embeddings.\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m usr_x, itm_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagation(usr_x, itm_x,\n\u001b[1;32m    152\u001b[0m     usr_edge_index\u001b[39m=\u001b[39;49musr_edge_index,\n\u001b[1;32m    153\u001b[0m     itm_edge_index\u001b[39m=\u001b[39;49mitm_edge_index\n\u001b[1;32m    154\u001b[0m )\n\u001b[1;32m    155\u001b[0m \u001b[39m# Returns the LGC embeddings.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mreturn\u001b[39;00m usr_x, itm_x\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Code/GNN-CF/project/model/light_gcn.py:79\u001b[0m, in \u001b[0;36mLGCProp.forward\u001b[0;34m(self, usr_x, itm_x, usr_edge_index, itm_edge_index)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[1;32m     72\u001b[0m     usr_x: Tensor,\n\u001b[1;32m     73\u001b[0m     itm_x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     77\u001b[0m     \u001b[39m# Updates the edge indices to be undirected.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mundirected:\n\u001b[0;32m---> 79\u001b[0m         usr_edge_index \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mmake_undirected(\n\u001b[1;32m     80\u001b[0m             src_edge_index\u001b[39m=\u001b[39;49musr_edge_index, \n\u001b[1;32m     81\u001b[0m             dst_edge_index\u001b[39m=\u001b[39;49mitm_edge_index\n\u001b[1;32m     82\u001b[0m         )\n\u001b[1;32m     83\u001b[0m         itm_edge_index \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mmake_undirected(\n\u001b[1;32m     84\u001b[0m             src_edge_index\u001b[39m=\u001b[39mitm_edge_index, \n\u001b[1;32m     85\u001b[0m             dst_edge_index\u001b[39m=\u001b[39musr_edge_index\n\u001b[1;32m     86\u001b[0m         )\n\u001b[1;32m     87\u001b[0m     \u001b[39m# Generates the edge weights for both node types.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Code/GNN-CF/project/model/utils.py:81\u001b[0m, in \u001b[0;36mmake_undirected\u001b[0;34m(src_edge_index, dst_edge_index)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_undirected\u001b[39m(\n\u001b[1;32m     75\u001b[0m     src_edge_index: Tensor, \n\u001b[1;32m     76\u001b[0m     dst_edge_index: Tensor\n\u001b[1;32m     77\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mhstack([\n\u001b[1;32m     79\u001b[0m         src_edge_index, \n\u001b[1;32m     80\u001b[0m         dst_edge_index\u001b[39m.\u001b[39;49mflip(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m---> 81\u001b[0m     ])\u001b[39m.\u001b[39;49munique(\u001b[39msorted\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:820\u001b[0m, in \u001b[0;36mTensor.unique\u001b[0;34m(self, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    811\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    812\u001b[0m         Tensor\u001b[39m.\u001b[39munique,\n\u001b[1;32m    813\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    818\u001b[0m         dim\u001b[39m=\u001b[39mdim,\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 820\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49munique(\n\u001b[1;32m    821\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    822\u001b[0m     \u001b[39msorted\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39msorted\u001b[39;49m,\n\u001b[1;32m    823\u001b[0m     return_inverse\u001b[39m=\u001b[39;49mreturn_inverse,\n\u001b[1;32m    824\u001b[0m     return_counts\u001b[39m=\u001b[39;49mreturn_counts,\n\u001b[1;32m    825\u001b[0m     dim\u001b[39m=\u001b[39;49mdim,\n\u001b[1;32m    826\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    483\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 484\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    483\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 484\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/functional.py:885\u001b[0m, in \u001b[0;36m_return_output\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39minput\u001b[39m):\n\u001b[1;32m    883\u001b[0m     \u001b[39mreturn\u001b[39;00m _unique_impl(\u001b[39minput\u001b[39m, \u001b[39msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[0;32m--> 885\u001b[0m output, _, _ \u001b[39m=\u001b[39m _unique_impl(\u001b[39minput\u001b[39;49m, \u001b[39msorted\u001b[39;49m, return_inverse, return_counts, dim)\n\u001b[1;32m    886\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/functional.py:791\u001b[0m, in \u001b[0;36m_unique_impl\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    787\u001b[0m         unique, (\u001b[39minput\u001b[39m,), \u001b[39minput\u001b[39m, \u001b[39msorted\u001b[39m\u001b[39m=\u001b[39m\u001b[39msorted\u001b[39m, return_inverse\u001b[39m=\u001b[39mreturn_inverse,\n\u001b[1;32m    788\u001b[0m         return_counts\u001b[39m=\u001b[39mreturn_counts, dim\u001b[39m=\u001b[39mdim)\n\u001b[1;32m    790\u001b[0m \u001b[39mif\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 791\u001b[0m     output, inverse_indices, counts \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49munique_dim(\n\u001b[1;32m    792\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    793\u001b[0m         dim,\n\u001b[1;32m    794\u001b[0m         \u001b[39msorted\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39msorted\u001b[39;49m,\n\u001b[1;32m    795\u001b[0m         return_inverse\u001b[39m=\u001b[39;49mreturn_inverse,\n\u001b[1;32m    796\u001b[0m         return_counts\u001b[39m=\u001b[39;49mreturn_counts,\n\u001b[1;32m    797\u001b[0m     )\n\u001b[1;32m    798\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    799\u001b[0m     output, inverse_indices, counts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_unique2(\n\u001b[1;32m    800\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m    801\u001b[0m         \u001b[39msorted\u001b[39m\u001b[39m=\u001b[39m\u001b[39msorted\u001b[39m,\n\u001b[1;32m    802\u001b[0m         return_inverse\u001b[39m=\u001b[39mreturn_inverse,\n\u001b[1;32m    803\u001b[0m         return_counts\u001b[39m=\u001b[39mreturn_counts,\n\u001b[1;32m    804\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Constucts the output path.\n",
    "if MODEL == 'LightGCN':\n",
    "    model_dir = 'light_gcn'\n",
    "else:\n",
    "    model_dir = 'mf'\n",
    "out_path = PATH.format(\n",
    "    strategy=STRATEGY,\n",
    "    model=model_dir, \n",
    "    reg_factor=REG_FACTOR\n",
    ")\n",
    "\n",
    "# Potentially initiates the training session.\n",
    "if TRAIN:\n",
    "    utils.dispatch_session(\n",
    "        module=module,\n",
    "        update_fn=update_fn,\n",
    "        validate_fn=validate_fn,\n",
    "        verbose=True,\n",
    "        num_epochs=32,\n",
    "        path=out_path\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the training (and validation) loss traces.\n",
    "path = os.path.join(out_path, 'trc.pkl')\n",
    "with open(path, 'rb') as file:\n",
    "    trace = pickle.load(file)\n",
    "# Defaulting to the last epoch.\n",
    "epoch_id = len(trace['update'])\n",
    "# Possibly infering the epoch with smallest validation loss.\n",
    "if STRATEGY == 'binary':\n",
    "    _, epoch_id = min([\n",
    "        (value, index)\n",
    "            for index, value\n",
    "            in enumerate(trace['validate'], \n",
    "                start=1\n",
    "            )\n",
    "    ])\n",
    "# Loads that epoch's parameters.\n",
    "path = os.path.join(out_path, f'mdl/{epoch_id:02d}.pt')\n",
    "state_dict = torch.load(path)\n",
    "# Assigns those parameters to the model.\n",
    "module.load_state_dict(state_dict)\n",
    "\n",
    "# Fetches a device.\n",
    "device = utils.get_device()\n",
    "# Computes the top-k recommended items of the model.\n",
    "ranking = rank_fn(module, \n",
    "    device=device, \n",
    "    verbose=True\n",
    ")\n",
    "# Saving the top-k ranking.\n",
    "path = os.path.join(out_path, 'rnk.pkl')\n",
    "object = tuple(ranking)\n",
    "with open(path, 'wb') as file:\n",
    "    pickle.dump(object, file)\n",
    "\n",
    "# Loading the top-k ranking.\n",
    "path = os.path.join(out_path, 'rnk.pkl')\n",
    "with open(path, 'rb') as file:\n",
    "    _, label, total, _, _ = pickle.load(file)\n",
    "# Scores the top-k ranking.\n",
    "scores = utils.composite_score(label, total,\n",
    "    score_fns=[\n",
    "        utils.recall_score,\n",
    "        utils.ndcg_score\n",
    "    ]\n",
    ")\n",
    "# Outputs the last epoch's scores.\n",
    "print('Score({})'.format(', '.join([\n",
    "    '{:.2%}'.format(score) for score in scores\n",
    "])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the found scores for the two different models.\n",
    "```\n",
    "LightGCN:\n",
    "    BPR(1e-3): Score(12.07%, 7.82%)\n",
    "    BPR(1e-4): Score(12.70%, 7.65%)\n",
    "    BPR(1e-5): Score(12.32%, 7.66%)\n",
    "    BPR(1e-6): Score(12.42%, 7.65%)\n",
    "    BCE(mini): Score(10.21%, 4.73%)\n",
    "MF:\n",
    "    BPR(1e-3): Score(11.21%, 7.68%)\n",
    "    BPR(1e-4): Score(11.01%, 7.52%)\n",
    "    BPR(1e-5): Score(11.68%, 7.91%)\n",
    "    BPR(1e-6): Score(11.37%, 7.71%)\n",
    "    BCE(mini): Score( 6.96%, 3.75%)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the plotting style.\n",
    "sns.set()\n",
    "\n",
    "# Loads the data.\n",
    "frames = []\n",
    "for loss, model, path in [\n",
    "    ['BCE', 'MF',       PATH.format(strategy='binary',  model='mf',        reg_factor=0)],\n",
    "    ['BCE', 'LightGCN', PATH.format(strategy='binary',  model='light_gcn', reg_factor=0)],\n",
    "    ['BPR', 'MF',       PATH.format(strategy='triplet', model='mf',        reg_factor=1e-5)],\n",
    "    ['BPR', 'LightGCN', PATH.format(strategy='triplet', model='light_gcn', reg_factor=1e-4)],\n",
    "]:\n",
    "    path = os.path.join(path, 'trc.pkl')\n",
    "    with open(path, 'rb') as file:\n",
    "        trace = pickle.load(file)\n",
    "    frame = DataFrame(trace) \\\n",
    "        .rename(columns={'update': 'Train', 'validate': 'Validation'}) \\\n",
    "        .rename_axis(index='epoch', columns='dataset') \\\n",
    "        .stack() \\\n",
    "        .rename('loss') \\\n",
    "        .reset_index() \\\n",
    "        .assign(objective=loss, model=model)\n",
    "    frames.append(frame)\n",
    "frame = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# Specifing which training configuration to be plotted.\n",
    "model, objective = 'LightGCN', 'BCE'\n",
    "# Plots the figure.\n",
    "data = frame.query(f'model == \"{model}\" & objective == \"{objective}\"')\n",
    "if model == 'MF' and objective == 'BCE':\n",
    "    figsize = [3.25, 3]\n",
    "else:\n",
    "    figsize = [3.25 * .965, 3]\n",
    "fig, ax = plt.subplots(\n",
    "    figsize=figsize, \n",
    "    dpi=256,\n",
    "    tight_layout=True\n",
    ")\n",
    "ax = sns.lineplot(\n",
    "    data=data, \n",
    "    x='epoch',\n",
    "    y='loss',\n",
    "    hue='dataset',\n",
    "    style='dataset',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_xlabel('Epoch')\n",
    "if model == 'MF' and objective == 'BCE':\n",
    "    ax.set_ylabel('Loss')\n",
    "else:\n",
    "    ax.set_ylabel(None)\n",
    "if model == 'LightGCN' and objective == 'BPR':\n",
    "    ax.legend(title='Dataset')\n",
    "else:\n",
    "    ax.get_legend().remove()\n",
    "plt.savefig(\n",
    "    fname=f'out/figures/{objective}-{model}.png',\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0\n",
    ")\n",
    "plt.show(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
