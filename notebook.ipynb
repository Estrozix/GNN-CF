{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namespace\n",
    "import torch.nn.functional as f\n",
    "import torch_geometric as pyg\n",
    "import itertools as it\n",
    "# import networkx as nx\n",
    "import torch\n",
    "\n",
    "# Constructor.\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.typing import EdgeType, NodeType\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch.nn.modules.loss import _Loss as Loss\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, Optimizer\n",
    "from torch.nn import (\n",
    "    Dropout1d,\n",
    "    Embedding, \n",
    "    Module, \n",
    "    ModuleDict,\n",
    "    ModuleList, \n",
    "    Linear, \n",
    "    LeakyReLU\n",
    ")\n",
    "from torch import Tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the target edge.\n",
    "TRG_EDGE = ('user', 'rated', 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the data.\n",
    "data = torch.load('data/out/Video_Games.pt')\n",
    "# Removes superfluous attributes, to save memory.\n",
    "del data['rated'].edge_attr\n",
    "del data['rated_by'].edge_attr\n",
    "# Sets the node and edge IDs.\n",
    "data.generate_ids()\n",
    "\n",
    "# Defines the final graph transformations.\n",
    "transform = RandomLinkSplit(\n",
    "    num_test=.1,\n",
    "    num_val=.1,\n",
    "    is_undirected=True, \n",
    "    add_negative_train_samples=False,\n",
    "    neg_sampling_ratio=0.,\n",
    "    edge_types=('user', 'rated', 'item'),\n",
    "    rev_edge_types=('item', 'rated_by', 'user')\n",
    ")\n",
    "# Splits the set into training, validation and testing.\n",
    "trn_data, vld_data, tst_data = transform(data)\n",
    "\n",
    "# Specifies the shared key-word arguments for the batch loaders..\n",
    "kwargs = dict(\n",
    "    num_neighbors=[0],  # [8, 4, 2],\n",
    "    neg_sampling='triplet',\n",
    "    num_workers=10,\n",
    "    shuffle=True,\n",
    "    # pin_memory=True\n",
    ")\n",
    "# Extracts the edge attribute indices for all datasets.\n",
    "trn_edge_label_index = trn_data[TRG_EDGE].edge_label_index\n",
    "vld_edge_label_index = vld_data[TRG_EDGE].edge_label_index\n",
    "tst_edge_label_index = tst_data[TRG_EDGE].edge_label_index\n",
    "# Creates the sub-graph loaders.\n",
    "trn_loader = LinkNeighborLoader(**kwargs,\n",
    "    data=trn_data,\n",
    "    edge_label_index=[TRG_EDGE, trn_edge_label_index],\n",
    "    batch_size=2048\n",
    ")\n",
    "vld_loader = LinkNeighborLoader(**kwargs,\n",
    "    data=vld_data,\n",
    "    edge_label_index=[TRG_EDGE, vld_edge_label_index],\n",
    "    batch_size=2048\n",
    ")\n",
    "tst_loader = LinkNeighborLoader(**kwargs,\n",
    "    data=tst_data,\n",
    "    edge_label_index=[TRG_EDGE, tst_edge_label_index],\n",
    "    batch_size=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_loader = LinkNeighborLoader(\n",
    "#     data=trn_data,\n",
    "#     edge_label_index=[('user', 'rated', 'item'), trn_edge_label_index],\n",
    "#     num_neighbors=[16, 8],\n",
    "#     neg_sampling='binary',\n",
    "#     num_workers=10,\n",
    "#     batch_size=64,\n",
    "#     shuffle=True,\n",
    "#     pin_memory=True\n",
    "# )\n",
    "# batch = next(iter(tmp_loader))\n",
    "# batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgePredictor(Module):\n",
    "\n",
    "    def __init__(self, *, trg_edge: EdgeType = TRG_EDGE) -> None:\n",
    "        super().__init__()\n",
    "        self.trg_edge = trg_edge\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def trg_src_node(self) -> NodeType:\n",
    "        return self.trg_edge[0]\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def trg_edge_name(self) -> str:\n",
    "        return self.trg_edge[1]\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def trg_dst_node(self) -> NodeType:\n",
    "        return self.trg_edge[2]\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def trg_nodes(self) -> tuple[NodeType, NodeType]:\n",
    "        return (self.trg_src_node, self.trg_dst_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeEmbedding(ModuleDict):\n",
    "\n",
    "    def __init__(self, \n",
    "        num_embeddings: dict[NodeType, int],\n",
    "        embedding_dim: int,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__({\n",
    "            node_type: Embedding(\n",
    "                num_embeddings=num_embeddings,\n",
    "                embedding_dim=embedding_dim, \n",
    "                **kwargs\n",
    "            ) \n",
    "                for node_type, num_embeddings \n",
    "                in num_embeddings.items()\n",
    "        })\n",
    "\n",
    "\n",
    "    def forward(self, n_id_dict: dict[NodeType, Tensor]) -> dict[NodeType, Tensor]:\n",
    "        return {\n",
    "            node_type: self[node_type](n_id) \n",
    "                for node_type, n_id \n",
    "                in n_id_dict.items()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InnerProduct(Module): \n",
    "\n",
    "    def forward(self, x_src: Tensor, x_dst: Tensor) -> Tensor:\n",
    "        return torch.bmm(\n",
    "            x_src.unsqueeze(-2),\n",
    "            x_dst.unsqueeze(-1)\n",
    "        ).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeRegressor(Linear):\n",
    "\n",
    "    def __init__(self, in_dim: int, out_dim: int = 1, bias: bool = False, **kwargs) -> None:\n",
    "        super().__init__(\n",
    "            in_features=in_dim,\n",
    "            out_features=out_dim,\n",
    "            bias=bias,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.weight.data = torch.nn.init.ones_(self.weight.data)\n",
    "        if self.bias:\n",
    "            self.bias.data = torch.nn.init.zeros_(self.bias.data)\n",
    "\n",
    "\n",
    "    def forward(self, x_src: Tensor, x_dst: Tensor) -> Tensor:\n",
    "        return super().forward(x_src * x_dst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(EdgePredictor):\n",
    "\n",
    "    def __init__(self, \n",
    "            num_embeddings: dict[NodeType, int], \n",
    "            embedding_dim: int,\n",
    "            *,\n",
    "            trg_edge: EdgeType,\n",
    "            **kwargs\n",
    "        ) -> None:\n",
    "        super().__init__(trg_edge=trg_edge)\n",
    "        self.embedding = NodeEmbedding(\n",
    "            num_embeddings=num_embeddings, \n",
    "            embedding_dim=embedding_dim,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.regressor = InnerProduct()\n",
    "        \n",
    "\n",
    "    def forward(self, \n",
    "        n_id: dict[NodeType, Tensor], \n",
    "        edge_label_index: dict[EdgeType, Tensor], \n",
    "    ) -> Tensor:\n",
    "        # Constructs the embeddings.\n",
    "        x_src, x_dst = self.embedding({\n",
    "            node_type: n_id[node_type] \n",
    "            for node_type \n",
    "            in self.trg_nodes\n",
    "        }).values()\n",
    "        # Extracts the edges to predict.\n",
    "        i_src, i_dst = edge_label_index[self.trg_edge]\n",
    "        # Computes and returns the predicted scores.\n",
    "        return self.regressor(x_src[i_src], x_dst[i_dst])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(EdgePredictor):\n",
    "\n",
    "    def __init__(self, \n",
    "            num_embeddings: dict[NodeType, int], \n",
    "            embedding_dim: int,\n",
    "            *,\n",
    "            trg_edge: EdgeType,\n",
    "            **kwargs\n",
    "        ) -> None:\n",
    "        super().__init__(trg_edge=trg_edge)\n",
    "        self.embedding = NodeEmbedding(\n",
    "            num_embeddings=num_embeddings, \n",
    "            embedding_dim=embedding_dim,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.regressor = EdgeRegressor(\n",
    "            in_dim=embedding_dim\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, \n",
    "        n_id: dict[NodeType, Tensor], \n",
    "        edge_label_index: dict[EdgeType, Tensor], \n",
    "    ) -> Tensor:\n",
    "        # Constructs the embeddings.\n",
    "        x_src, x_dst = self.embedding({\n",
    "            node_type: n_id[node_type] \n",
    "            for node_type \n",
    "            in self.trg_nodes\n",
    "        }).values()\n",
    "        # Extracts the edges to predict.\n",
    "        i_src, i_dst = edge_label_index[self.trg_edge]\n",
    "        # Computes and returns the predicted scores.\n",
    "        return self.regressor(x_src[i_src], x_dst[i_dst])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Graph Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingPropagationCell(Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "        in_dim: int,\n",
    "        out_dim: int = None, \n",
    "        bias: bool = False,\n",
    "        dropout: float = .5\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.drop = Dropout1d(dropout)\n",
    "        self.loop = Linear(in_dim, out_dim or in_dim, bias=bias)\n",
    "        self.intr = Linear(in_dim, out_dim or in_dim, bias=bias)\n",
    "        self.actv = LeakyReLU()\n",
    "\n",
    "    \n",
    "    def forward(self, \n",
    "        x_src: Tensor, \n",
    "        x_dst: Tensor, \n",
    "        edge_index: Tensor,\n",
    "        edge_weight: Tensor = None\n",
    "    ) -> Tensor:\n",
    "        # Applies the node dropout.\n",
    "        x_src = self.drop(x_src)  # node dropout\n",
    "        x_dst = self.drop(x_dst)  # node dropout\n",
    "        # Computes the messages to pass.\n",
    "        i_src, i_dst = edge_index\n",
    "        z_src = self.loop(x_src)[i_src]\n",
    "        z_int = self.intr(x_src[i_src] * x_dst[i_dst])\n",
    "        z_msg = edge_weight * (z_src + z_int)\n",
    "        z_msg = self.drop(z_msg)  # message dropout\n",
    "        z_sum = pyg.utils.scatter(z_msg, i_dst, \n",
    "            dim_size=x_dst.size(0)\n",
    "        )\n",
    "        # Computes the self-messages.\n",
    "        z_dst = self.loop(x_dst)\n",
    "        z_dst = self.drop(z_dst)  # message dropout\n",
    "        # Computes the new embeddings and returns them.\n",
    "        x_new = self.actv(z_dst + z_sum)\n",
    "        return x_new\n",
    "    \n",
    "\n",
    "class EmbeddingPropagationLayer(ModuleDict):\n",
    "\n",
    "    def __init__(self, \n",
    "            edge_types: list[EdgeType], \n",
    "            in_dim: int, \n",
    "            out_dim: int = None, \n",
    "            **kwargs\n",
    "        ) -> None:\n",
    "        super().__init__({\n",
    "            edge_label: EmbeddingPropagationCell(\n",
    "                in_dim=in_dim, \n",
    "                out_dim=out_dim, \n",
    "                **kwargs\n",
    "            )\n",
    "                for (_, edge_label, _)\n",
    "                in edge_types\n",
    "        })\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "        x: dict[NodeType, Tensor], \n",
    "        edge_index: dict[EdgeType, Tensor], \n",
    "        edge_weight: dict[EdgeType, Tensor]\n",
    "    ) -> dict[NodeType, Tensor]:\n",
    "        return {\n",
    "            dst_node: self[edge_label](\n",
    "                x_src=x[src_node], \n",
    "                x_dst=x[dst_node], \n",
    "                edge_index=edge_index[\n",
    "                    src_node, edge_label, dst_node\n",
    "                ],\n",
    "                edge_weight=edge_weight[\n",
    "                    src_node, edge_label, dst_node\n",
    "                ]\n",
    "            )\n",
    "                for src_node, edge_label, dst_node \n",
    "                in edge_index\n",
    "        }\n",
    "    \n",
    "\n",
    "class EmbeddingPropagation(ModuleList):\n",
    "    \n",
    "    def __init__(self, \n",
    "        embedding_dims: list[int], \n",
    "        edge_types: list[EdgeType],\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__([\n",
    "            EmbeddingPropagationLayer(\n",
    "                edge_types=edge_types,\n",
    "                in_dim=in_dim,\n",
    "                out_dim=out_dim,\n",
    "                **kwargs\n",
    "            ) \n",
    "                for in_dim, out_dim \n",
    "                in it.pairwise(embedding_dims)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "        x: dict[NodeType, Tensor], \n",
    "        edge_index: dict[EdgeType, Tensor]\n",
    "    ) -> dict[NodeType, Tensor]:\n",
    "        # Constructs the edge weights.\n",
    "        edge_weight = {\n",
    "            edge_type: (\n",
    "                pyg.utils.degree(i_src)[i_src]\n",
    "                *\n",
    "                pyg.utils.degree(i_dst)[i_dst]\n",
    "            ).pow(-.5).unsqueeze(-1)\n",
    "            for edge_type, (i_src, i_dst)\n",
    "            in edge_index.items()\n",
    "        }\n",
    "        # Applies the embedding propagation layers.\n",
    "        xs = [x]\n",
    "        for module in self:\n",
    "            x = module(x, edge_index, edge_weight)\n",
    "            xs.append(x)\n",
    "        # Concatenates all layers' embeddings and returns them.\n",
    "        x_new = {\n",
    "            node_type: torch.cat([\n",
    "                    x_[node_type] for x_ in xs\n",
    "            ], dim=-1) for node_type in x.keys()\n",
    "        }\n",
    "        return x_new\n",
    "    \n",
    "\n",
    "class EdgeRegressor(Linear): \n",
    "\n",
    "    def __init__(self, \n",
    "        in_features: int,\n",
    "        out_features: int = 1,\n",
    "        *,\n",
    "        bias: bool = True,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(in_features, out_features, bias=bias, **kwargs)\n",
    "\n",
    "\n",
    "    def forward(self, x_src: Tensor, x_dst: Tensor) -> Tensor:\n",
    "        return super().forward(x_src * x_dst)\n",
    "\n",
    "\n",
    "# class EdgeRegressor(Module): \n",
    "\n",
    "#     def forward(self, x_src: Tensor, x_dst: Tensor) -> Tensor:\n",
    "#         return (x_src * x_dst).sum(-1)\n",
    "    \n",
    "    \n",
    "class NGCF(Module): \n",
    "\n",
    "    def __init__(self, \n",
    "        num_embeddings: dict[NodeType, int], \n",
    "        embedding_dims: list[int], \n",
    "        *,\n",
    "        edge_types: list[EdgeType],\n",
    "        src_node: NodeType,\n",
    "        dst_node: NodeType,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = NodeEmbedding(\n",
    "            num_embeddings=num_embeddings, \n",
    "            embedding_dim=embedding_dims[0]\n",
    "        )\n",
    "        self.propagation = EmbeddingPropagation(\n",
    "            embedding_dims=embedding_dims, \n",
    "            edge_types=edge_types,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.regressor = EdgeRegressor(\n",
    "            in_features=sum(embedding_dims)\n",
    "        )\n",
    "        # self.regressor = EdgeRegressor()\n",
    "        self.src_node = src_node\n",
    "        self.dst_node = dst_node\n",
    "    \n",
    "\n",
    "    def forward(self, \n",
    "            n_id: dict[NodeType, Tensor],\n",
    "            edge_index: dict[EdgeType, Tensor],\n",
    "            edge_label_index: Tensor\n",
    "        ) -> Tensor:\n",
    "        # Generates and propagates the node embeddings.\n",
    "        x = self.embedding(n_id)\n",
    "        x = self.propagation(x, edge_index)\n",
    "        # Computes the rank predictions and returns them.\n",
    "        y = self.regressor(\n",
    "            x[self.src_node][edge_label_index[0]], \n",
    "            x[self.dst_node][edge_label_index[1]]\n",
    "        )\n",
    "        # Returns the modified dataset.\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispatch_epoch(\n",
    "    module: type[Module], \n",
    "    loader: type[DataLoader],\n",
    "    criterion: type[Loss],\n",
    "    *,\n",
    "    batch_handler: callable,\n",
    "    optimizer: type[Optimizer] = None, \n",
    "    device: torch.device = None,\n",
    "    verbose: bool | int = None\n",
    ") -> list[float]:\n",
    "\n",
    "    # Ensures a device is specified.\n",
    "    if device is None:\n",
    "        device = torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        )\n",
    "    # Sends the model to the specified device.\n",
    "    module = module.to(device)\n",
    "\n",
    "    # Initializes the data structures for the verbose output.\n",
    "    if verbose:\n",
    "        cum_loss = 0\n",
    "\n",
    "    # Initializes the loss trace buffer.\n",
    "    loss_trace = []\n",
    "    # Iterates over the data-loader's batches.\n",
    "    for batch_id, batch in enumerate(loader, start=1):\n",
    "\n",
    "        # Resets the gradient if an optimizer exists.\n",
    "        if optimizer:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Constructs the design and target data structures.\n",
    "        loss = batch_handler(module, batch, criterion, \n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Updates the module, if an optimizer has been given\n",
    "        if optimizer:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Logs the computed loss.\n",
    "        loss = loss.item()\n",
    "        loss_trace.append(loss)\n",
    "        \n",
    "        # Handles the verbose messaging, if verbose is set.\n",
    "        if verbose:\n",
    "            # Updates the cumulative loss sum.\n",
    "            cum_loss += loss\n",
    "            # Outputs the current statistics, if the correct index is present.\n",
    "            if batch_id % verbose == 0:\n",
    "                # Updates the tracked statistics.\n",
    "                avg_loss = cum_loss / batch_id\n",
    "                # Outputs the tracked staistics.\n",
    "                print(\n",
    "                    f'Batch({batch_id}): '\n",
    "                    f'CumAvgLoss({avg_loss:.4f}) & '\n",
    "                    f'BatchLoss({loss:.4f})',\n",
    "                    end='\\r',\n",
    "                    flush=True\n",
    "                )\n",
    "    \n",
    "    # Returns the traced loss.\n",
    "    return loss_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_handler(\n",
    "        data: HeteroData, \n",
    "        x: dict[NodeType, Tensor],\n",
    "        *,\n",
    "        src_node: NodeType,\n",
    "        dst_node: NodeType\n",
    "    ) -> tuple[Tensor, Tensor, Tensor]:\n",
    "    \n",
    "    # Extracts the source and destination nodes' indices.\n",
    "    i_src = data[src_node].src_index\n",
    "    i_pos = data[dst_node].dst_pos_index\n",
    "    i_neg = data[dst_node].dst_neg_index\n",
    "\n",
    "    # Constructs the node types' feature matrices.\n",
    "    x_src = x[src_node][i_src]\n",
    "    x_pos = x[dst_node][i_pos]\n",
    "    x_neg = x[dst_node][i_neg]\n",
    "\n",
    "    # Returns the source, positive and negative features.\n",
    "    return x_src, x_pos, x_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mf_handler(\n",
    "    module: type[EdgePredictor], \n",
    "    data: HeteroData, \n",
    "    criterion: type[Loss],\n",
    "    *,\n",
    "    device: torch.device\n",
    ") -> Tensor:\n",
    "    \n",
    "    # Sends the items to the correct device.\n",
    "    data = data.to(device)\n",
    "    # Computes the embedding propegation.\n",
    "    x = module.embedding(data.n_id_dict)\n",
    "\n",
    "    # Extracts the node target features.\n",
    "    x_src, x_pos, x_neg = triplet_handler(data, x,\n",
    "        src_node=module.trg_src_node,\n",
    "        dst_node=module.trg_dst_node\n",
    "    )\n",
    "\n",
    "    # Computes the link scores.\n",
    "    y_pos = module.regressor(x_src, x_pos)\n",
    "    y_neg = module.regressor(x_src, x_neg)\n",
    "    # Computes the loss.\n",
    "    loss = criterion(y_pos, y_neg)\n",
    "\n",
    "    # Returns the loss.\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRLoss(Loss):\n",
    "\n",
    "    def forward(self, y_pos: Tensor, y_neg: Tensor) -> Tensor:\n",
    "        return - f.logsigmoid(y_pos - y_neg).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MF(\n",
       "  (embedding): NodeEmbedding(\n",
       "    (user): Embedding(1540618, 16)\n",
       "    (item): Embedding(71982, 16)\n",
       "  )\n",
       "  (regressor): InnerProduct()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = next(iter(trn_loader))\n",
    "model = MF(\n",
    "    num_embeddings=data.num_nodes_dict,\n",
    "    embedding_dim=16,\n",
    "    trg_edge=TRG_EDGE\n",
    ")\n",
    "display(model)\n",
    "\n",
    "# Instanciates the learning algorithm and loss criterion.\n",
    "optimizer = Adam(model.parameters(), \n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-6\n",
    ")\n",
    "criterion = BPRLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(1)\n",
      "Batch(992): CumAvgLoss(1.7614) & BatchLoss(1.3771)\n",
      "Batch(96): CumAvgLoss(1.4220) & BatchLoss(1.3724)\n",
      "Epoch(2)\n",
      "Batch(992): CumAvgLoss(1.4850) & BatchLoss(1.4232)\n",
      "Batch(96): CumAvgLoss(1.1411) & BatchLoss(1.1724)\n",
      "Epoch(3)\n",
      "Batch(992): CumAvgLoss(1.2985) & BatchLoss(1.2532)\n",
      "Batch(96): CumAvgLoss(1.0223) & BatchLoss(1.0516)\n",
      "Epoch(4)\n",
      "Batch(992): CumAvgLoss(1.1488) & BatchLoss(1.1160)\n",
      "Batch(96): CumAvgLoss(0.9575) & BatchLoss(0.9664)\n",
      "Epoch(5)\n",
      "Batch(992): CumAvgLoss(1.0259) & BatchLoss(1.0278)\n",
      "Batch(96): CumAvgLoss(0.9126) & BatchLoss(0.9366)\n",
      "Epoch(6)\n",
      "Batch(992): CumAvgLoss(0.9233) & BatchLoss(0.9253)\n",
      "Batch(96): CumAvgLoss(0.8710) & BatchLoss(0.8660)\n",
      "Epoch(7)\n",
      "Batch(992): CumAvgLoss(0.8391) & BatchLoss(0.8313)\n",
      "Batch(96): CumAvgLoss(0.8397) & BatchLoss(0.8551)\n",
      "Epoch(8)\n",
      "Batch(992): CumAvgLoss(0.7676) & BatchLoss(0.7471)\n",
      "Batch(96): CumAvgLoss(0.8104) & BatchLoss(0.7979)\n",
      "Epoch(9)\n",
      "Batch(992): CumAvgLoss(0.7087) & BatchLoss(0.7072)\n",
      "Batch(96): CumAvgLoss(0.7901) & BatchLoss(0.7966)\n",
      "Epoch(10)\n",
      "Batch(992): CumAvgLoss(0.6590) & BatchLoss(0.6611)\n",
      "Batch(96): CumAvgLoss(0.7704) & BatchLoss(0.7614)\n",
      "Epoch(11)\n",
      "Batch(992): CumAvgLoss(0.6161) & BatchLoss(0.6056)\n",
      "Batch(96): CumAvgLoss(0.7552) & BatchLoss(0.7389)\n",
      "Epoch(12)\n",
      "Batch(992): CumAvgLoss(0.5780) & BatchLoss(0.5960)\n",
      "Batch(96): CumAvgLoss(0.7420) & BatchLoss(0.7474)\n",
      "Epoch(13)\n",
      "Batch(992): CumAvgLoss(0.5443) & BatchLoss(0.5449)\n",
      "Batch(96): CumAvgLoss(0.7307) & BatchLoss(0.7378)\n",
      "Epoch(14)\n",
      "Batch(992): CumAvgLoss(0.5119) & BatchLoss(0.5281)\n",
      "Batch(96): CumAvgLoss(0.7212) & BatchLoss(0.7401)\n",
      "Epoch(15)\n",
      "Batch(992): CumAvgLoss(0.4809) & BatchLoss(0.4944)\n",
      "Batch(96): CumAvgLoss(0.7148) & BatchLoss(0.7221)\n",
      "Epoch(16)\n",
      "Batch(992): CumAvgLoss(0.4519) & BatchLoss(0.4656)\n",
      "Batch(96): CumAvgLoss(0.7082) & BatchLoss(0.7130)\n"
     ]
    }
   ],
   "source": [
    "# Clears the GPU cache.\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trn_trace = []\n",
    "vld_trace = []\n",
    "for epoch_id in range(1, 16+1):\n",
    "    print(f'Epoch({epoch_id})')\n",
    "\n",
    "    # Dispatches one epoch of training.\n",
    "    trn_loss = dispatch_epoch(\n",
    "        module=model,\n",
    "        loader=trn_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        batch_handler=mf_handler,\n",
    "        verbose=32\n",
    "    )\n",
    "    trn_trace.append(trn_loss)\n",
    "    print()\n",
    "\n",
    "    # Dispatches one epoch of validation.\n",
    "    with torch.no_grad():\n",
    "        vld_loss = dispatch_epoch(\n",
    "            module=model,\n",
    "            loader=vld_loader,\n",
    "            criterion=criterion,\n",
    "            batch_handler=mf_handler,\n",
    "            verbose=32\n",
    "        )\n",
    "    vld_trace.append(vld_loss)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([      1,       2,       4,  ..., 1540615, 1540616, 1540617])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_nodes, _ = trn_data['rated'].edge_index\n",
    "src_nodes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()\n",
    "batch = next(iter(vld_loader))\n",
    "with torch.no_grad():\n",
    "    x = model.embedding(batch.n_id_dict)\n",
    "x_src, x_pos, x_neg = triplet_handler(batch, x, \n",
    "    src_node=model.trg_src_node, \n",
    "    dst_node=model.trg_dst_node\n",
    ")\n",
    "with torch.no_grad():\n",
    "    y_pos = model.regressor(x_src, x_pos)\n",
    "    y_neg = model.regressor(x_src, x_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat([y_pos, y_neg])\n",
    "labels = torch.cat([\n",
    "    torch.ones_like(y_pos),\n",
    "    torch.zeros_like(y_neg)\n",
    "])\n",
    "indices = y.sort(descending=True).indices\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Precision @ K\n",
    "cum_ap = labels[:at_k].cumsum(0) / torch.arange(1, at_k + 1)\n",
    "ap = (labels[:at_k] * cum_ap).sum() / labels[:at_k].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8089)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@64(1.95%)\n"
     ]
    }
   ],
   "source": [
    "recall = labels[indices][:64].sum().item() / y_pos.size(0)\n",
    "print(f'R@64({recall:.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namespace.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Constructor.\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "# Setting the plotting style.\n",
    "sns.set()\n",
    "\n",
    "# Typing.\n",
    "TraceType = list[list[float]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trace(trace: TraceType) -> DataFrame:\n",
    "    return DataFrame(trace) \\\n",
    "        .rename_axis(index='epoch', columns='batch') \\\n",
    "        .transpose() \\\n",
    "        .stack() \\\n",
    "        .rename('loss') \\\n",
    "        .reset_index()\n",
    "\n",
    "\n",
    "def make_frame(traces: list[TraceType], *, labels: list[str]) -> DataFrame:\n",
    "    return pd.concat([\n",
    "        parse_trace(trace).assign(trace=label) \n",
    "        for label, trace in zip(labels, traces)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformats the loss traces.\n",
    "trace = make_frame(\n",
    "    traces=[trn_trace, vld_trace], \n",
    "    labels=['Train', 'Valid.']\n",
    ")\n",
    "\n",
    "# Plots the loss trace.\n",
    "fig, ax = plt.subplots(figsize=[7, 3], dpi=192)\n",
    "ax = sns.lineplot(\n",
    "    data=trace, \n",
    "    x='epoch', \n",
    "    y='loss', \n",
    "    hue='trace', \n",
    "    style='trace', \n",
    "    errorbar='sd', \n",
    "    ax=ax\n",
    ")\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Average Loss')\n",
    "ax.legend(title='Dataset')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngcf_handler(\n",
    "    module: type[Module], \n",
    "    data: HeteroData, \n",
    "    criterion: type[Loss],\n",
    "    *,\n",
    "    device: torch.device\n",
    ") -> Tensor:\n",
    "    \n",
    "    # Sends the items to the correct device.\n",
    "    data = data.to(device)\n",
    "\n",
    "    # Computes the embedding propegation.\n",
    "    x = module.embedding(data.n_id_dict)\n",
    "    x = module.propagation(x, data.edge_index_dict)\n",
    "    # Extracts the source nodes' features.\n",
    "    i_src = data['user'].src_index\n",
    "    x_src = x['user'][i_src]\n",
    "    # Constructs the positive and negative feature matrices.\n",
    "    i_pos = data['item'].dst_pos_index\n",
    "    i_neg = data['item'].dst_neg_index\n",
    "    x_pos = x['item'][i_pos]\n",
    "    x_neg = x['item'][i_neg]\n",
    "    # Computes the link scores.\n",
    "    y_pos = module.regressor(x_src, x_pos)\n",
    "    y_neg = module.regressor(x_src, x_neg)\n",
    "\n",
    "    # Computes the loss.\n",
    "    loss = criterion(y_pos, y_neg)\n",
    "\n",
    "    # Returns the loss.\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes the neural graph model.\n",
    "ngcf = NGCF(\n",
    "    num_embeddings=data.num_nodes_dict,\n",
    "    embedding_dims=[16] * 5,\n",
    "    edge_types=data.edge_types,\n",
    "    src_node='user',\n",
    "    dst_node='item',\n",
    "    dropout=.1,\n",
    ")\n",
    "display(ngcf)\n",
    "\n",
    "# Instanciates the learning algorithm and loss criterion.\n",
    "optimizer = Adam(ngcf.parameters(), \n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "criterion = BPRLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clears the GPU cache.\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trn_trace = []\n",
    "vld_trace = []\n",
    "for epoch_id in range(1, 16+1):\n",
    "    print(f'Epoch({epoch_id})')\n",
    "\n",
    "    # Dispatches one epoch of training.\n",
    "    trn_loss = dispatch_epoch(\n",
    "        module=ngcf,\n",
    "        loader=trn_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        batch_handler=ngcf_handler,\n",
    "        verbose=16\n",
    "    )\n",
    "    trn_trace.append(trn_loss)\n",
    "    print()\n",
    "\n",
    "    # Dispatches one epoch of validation.\n",
    "    with torch.no_grad():\n",
    "        vld_loss = dispatch_epoch(\n",
    "            module=ngcf,\n",
    "            loader=vld_loader,\n",
    "            criterion=criterion,\n",
    "            batch_handler=ngcf_handler,\n",
    "            verbose=16\n",
    "        )\n",
    "    vld_trace.append(vld_loss)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
